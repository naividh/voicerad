# VoiceRad Docker Compose
# CPU demo mode (default):  docker compose up
# GPU mode:                 docker compose --profile gpu up
# CPU with real models:     DEMO_MODE=false HF_TOKEN=hf_xxx docker compose up

version: "3.9"

services:
  backend:
    build: ./backend
    container_name: voicerad-backend
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      - ENV=development
      - DEMO_MODE=${DEMO_MODE:-true}
      - HF_TOKEN=${HF_TOKEN:-}
      - ALLOWED_ORIGINS=http://localhost:3000
    volumes:
      - ./backend:/app
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  # GPU-enabled backend (use with: docker compose --profile gpu up)
  backend-gpu:
    build:
      context: ./backend
      args:
        BASE_IMAGE: nvidia/cuda:12.1.0-runtime-ubuntu22.04
    container_name: voicerad-backend-gpu
    profiles: ["gpu"]
    ports:
      - "8000:8000"
    environment:
      - PORT=8000
      - ENV=development
      - DEMO_MODE=false
      - HF_TOKEN=${HF_TOKEN}
      - ALLOWED_ORIGINS=http://localhost:3000
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  frontend:
    build: ./frontend
    container_name: voicerad-frontend
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=http://localhost:8000
    volumes:
      - ./frontend/src:/app/src
      - ./frontend/public:/app/public
    depends_on:
      backend:
        condition: service_healthy
